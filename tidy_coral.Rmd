---
title: "Tidy Coral"
author: Julie Lowndes and Jeanette Clark
output:
  html_document:
    toc: true
    toc_float: true
---

## Overview

We are going to begin a tidy coral analysis that you will continue on your own. We'll be using what we learned in the [data-science-training](http://ohi-science.org/data-science-training/) but with real coral data from Oahu. 

Our plan is to combine benthic observation data with oceanographic buoy data and explore patterns. 

The benthic data comes from digital still images through the [Hawaii Coral Reef Assessment and Monitoring Program (CRAMP)](https://search.dataone.org/#view/{21548C09-57F9-449A-86B2-470A1DD4F0B5}), and the buoy data is from the [Kaneohe Bay NOAA buoy at Coconut Island (Station MOKH1)](http://www.ndbc.noaa.gov/station_history.php?station=mokh1).

We'll also be using a few new R packages that are super helpful: `stringr`, `janitor`, and `skimr`. 

**Objectives**

- put your data wrangling skills to practice
- read in two real datasets relevant to coral
- join these two datasets together
- learn that this is an iterative process and requires a lot of decisionmaking

## Setup

First off, let's open up a GitHub repo we were working in yesterday, and start a new RMarkdown file. I'll call mine tidy_coral_analysis.Rmd. 

I'll add a tiny bit of information to get us started, and you can fill in once you know more about what the analysis becomes: "Exploratory analysis to combine benthic observation data with oceanographic buoy data."

Then we'll add a setup chunk:

```{r setup, warning=FALSE, message=FALSE}
## libraries
library(tidyverse)
library(janitor) # install.packages('janitor')
library(skimr) # install.packages('skimr')
library(stringr) # added when we needed it for benthic data

## data filepaths/urls ----

## benthic data
benthic_filepath <- 'data/100308OaAla03m.CSV'

## buoy data
buoy_url <- 'http://www.ndbc.noaa.gov/view_text_file.php?filename=mokh1h2010.txt.gz&dir=data/historical/stdmet/'
```

## Benthic data

This is benthic data from a series of CRAMP (Coral Reef Assessment Monitoring Program) data that includes Kaneohe Bay coral survey still images and extracted data (with larger Hawaiian Islands context):

[2015. Hawaii Coral Reef Assessment and Monitoring Program (CRAMP): benthic data from digital still images made in 2008-2010 on Kauai, Oahu, Molokai, Maui, and Hawaii (NODC Accession 0104255). NOAA NCEI Oceanographic Data Archive.](https://search.dataone.org/#view/{6A218D8B-05CD-49EA-AC13-FD0372B3B1D4}) 

We have to navigate to [here](https://www.nodc.noaa.gov/archive/arc0054/0104255/1.1/data/0-data/cd05/Oahu/OaHan/) and download it; I've saved it in the /data folder.

### Import from a local file

Let's import and have a look with `head()` and the Environment pane.

```{r read_csv benthic, message=FALSE, results='hide'}
benthic_raw <- read_csv(benthic_filepath)
head(benthic_raw) 
```

There is a lot of columns that are all NA, but let's not worry about that right now. 

### Wrangle

Let's use the janitor package to clean up the column headers. Let's create a new `benthic` object with a pipe:

```{r janitor and skimr}
## the `janitor` package's `clean_names` function
benthic <- benthic_raw %>%
  janitor::clean_names()

names(benthic)
```

`janitor::clean_names()` is such a useful function for taking messy column headers and cleaning them up!

Let's pull out a few columns that look useful for working with and go from there. 

```{r select benthic}
benthic <- benthic %>%
  select(id_name, point, x, y, id_date)

head(benthic)
```

Great. But let's have another look at those dates. There are some weird `#`s leading and trailing the dates that will surely cause trouble later, and they don't look good. So let's remove them. We can create another column called simply "date". 

Let's go back up to the setup and add `library(stringr)` to the setup chunk and run it. 

```{r}
benthic <- benthic %>%
  mutate(date = stringr::str_remove_all(id_date, "#"))
```

### Explore

Now let's have a quick look at some summary stats:

```{r summary benthic, results='hide'}
summary(benthic)
```

```{r skim benthic}
skimr::skim(benthic)
```

`skimr::skim()` lets us see quickly that there are 6 unique dates and 16 unique species. It will also make cool histograms of continueous data, although we won't focus on that at the moment. 

Let's check out which species are represented. 

```{r unique species}
unique(benthic$id_name)
```

And to get a sense of our data let's just have a quick plot of species count by date: 

```{r plot benthic}
ggplot(benthic, aes(date, fill = id_name)) +
         geom_bar()
```

OK so there would be a lot of ways we could improve this plot (starting with color and how it is grouped!). But we just wanted a quick look. And this could help us frame our scientific questions later on. For example: 

- why do total counts increase so much through time?
- ...

Great! Let's leave this for a moment and read in the other data. 

## Buoy data

### Import from a url

Let's also have a look in the Environment pane as we read in the data.

```{r read_csv, message=FALSE, results='hide'}
buoy <- readr::read_csv(buoy_url)
head(buoy) # hmm this doesn't look right! Why not?
```

This imported just as one column. Why didn't that import properly? Let's have a look at the URL of the data. Ah right. It's a .txt, not a .csv. 

OK. `readr` should have a function to read in .txt files. Let's navigate to the help menu and have a look. In the bottom right RStudio pane, click on "Packages". Type `readr` in the search menu, then click on its name. This will let you see all of the functions within the package. 

There are a lot of options, but let's try `read_table`. It will return a dataframe.

```{r read_table, message=FALSE, results='hide'}
## read_table
buoy_raw <- read_table(buoy_url)
head(buoy) ## still not quite right -- missed some columns. 
```

Why might that be? What is the delimiter for this file? This is when, if I can, I would actually *look* at the file. I'm going to open the file in a text editor, or even copy-paste a few lines. I use TextWrangler. There, I can "show invisibles" and see what the delimiters are: 

<br> 

![](images/text_editor_show_invisibles.png)

<br> 

Here the dots show spaces (and a triangle would be a tab, not shown here). So I can see that there is mostly one space separating columns, but there are also up to 5 spaces! This kind of inconsistency can be a problem. This type of file is called a fixed width file.

But...luckily the `read_table2()` allows for this, because it "allows any number of whitespace characters between columns". Woop woop!

```{r, warning=FALSE, message=FALSE, results='hide'}
## read_table2
buoy_raw <- read_table2(buoy_url)
head(buoy_raw) ## this is what we need!
```

Great, this is what we needed for import!

In creating this tutorial, I actually tried a few other options that didn't work for various reasons. I spared us from trying this all together (in the interest of time) — but educational to see them and why they didn't work:

```{r read_delim, eval=FALSE}
## this just wasn't the right approach
buoy_test <- read_delim(buoy_url, delim = " ", trim_ws = TRUE, skip=1)
```

This is something I tried to illustrate when you should think to yourself "someone has figured out a better way to do this". I tried to force it and it involved way too many steps and workarounds, and saving a temporary copy of the data. Boo! This is super unideal. If you find yourself going down a road like this, stop, expect that you're not the first person to ever access data structured like this, and look for a better way!!!!

```{r read_lines, eval=FALSE}
buoy_test <- read_lines(buoy_url)
y <- buoy_test %>%
  as_data_frame() %>%
  mutate(value = str_replace_all(value, ' +', ',')) 
write_delim(y, 'data/buoy_local_copy.csv')

z <- read_csv('data/buoy_local_copy.csv', skip=1)
head(z) ## PRAISE BE
```

Cool. Nice that `read_table2` was designed to get the job done — we just have to expect that it exists and find it. 

### Wrangle

We've got `buoy_raw` as the raw data we read from online. Let's create a new variable called `buoy` that we'll wrangle instead of that raw data (especially nice if you've got poor internet and don't want to read it in each time!)
```{r}
buoy <- buoy_raw
```

Let's look at the column headers.
```{r, eval=FALSE}
names(buoy)
head(buoy)
```

OK. As we know, our data frame needs one column header. But we've actually got two rows of information about what the data represent. R thinks that the first row are the column headers, and it considers the second row data. Let's clean up those names. But we don't want to lose either of those rows, because they both have important and unique information (measurement and units). 

So, let's see if we can take that the first row of data (the units) and stick it on the with the column names (measurement). Then, we can get rid of that units row. 

In the `stringr` package, there is a way to combine strings using the `str_c` function. 

There's 3 things we want to do to these column names: 

1. make the column header a combo of rows 1 and 2
    - we want this to look like this: `currentheader_row1`. So we want to combine these two rows with a `_`
    - we want to identify row1 by name, not `buoy[1,]` because a) it's cryptic, and b) it will introduce silent problems if you run this code more than once
1. clean up the header; get rid of `#` and `/`
1. delete the now-redundant row 1

So let's start with the first step:

```{r clean col names, results='hide'}
## 1. overwrite column names
names(buoy) <- str_c(names(buoy),                  ## current header
                  buoy %>% filter(`#YY` == "#yr"), ## row1 -- don't say buoy[1,] 
                  sep = "_")                       ## separate by `_`

## inspect
names(buoy) ## Looks a lot better
```

Now the second step:

```{r, results='hide'}
## 2. clean up a bit more to get rid of the `#`s and the `/`s. 
names(buoy) <- str_replace_all(names(buoy), "#", "")  # replace `#` with nothing 
names(buoy) <- str_replace_all(names(buoy), "/", "_") # replace `/` with `_`

## inspect to make sure it worked
names(buoy)
```

Cool, that looks good enough for now!

Final step! Let's just have a look in the Environment pane to see how many rows there are now (84435 rows, 18 columns)
```{r}
## 3. remove redundant row with units
buoy <- buoy %>%
  filter(YY_yr != "#yr")
```

I saw it, did you? In the Environment pane it now says 84434x18. Let's have another look:

```{r, eval=FALSE}
head(buoy)
```

And what would happen if we reran this? 

```{r}
buoy <- buoy %>%
  filter(YY_yr != "#yr")
```

Nothing, which is great! But if we'd removed `buoy[1,]`, we'd lose a row of data (silently). 

### Explore

Since we want to analyze these temperatures to the benthic species from above, let's get a visual of what the temperature data looks like, and then we'll think about how this relates with the benthic species. 

#### Temperature

```{r plot buoy}
ggplot(buoy, aes(WTMP_degC)) +
  geom_bar()

## I googled how to rotate the tick label axis so that we can read the labels:
ggplot(buoy, aes(WTMP_degC)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90))

```

OK. So there is a lot to take in here. 

Consider this a **to do list** when you start working on your own. 

1. Seems like 999.0 is not really a measured °Celsius
  - After confirming with the metadata, we should replace it with NA `stringr::str_replace_all()`
1. `WTMP_degC` does not seem to be numeric (since 999.0 is right there next to 28.6).
  - We could confirm this with `str(buoy)`, then convert to numeric with `buoy <- buoy %>% mutate(WTMP_degC = as.numeric(WTMP_degC))`
  - Why is this a string? So actually all variables in `buoy` are character instead of numeric, and it's because when we originally read in the file the first row was measurement units, which was a character string. So any of these that we want to treat of numbers we are going to have to explicitly change to numeric. 

#### Dates

Let's have another look at the dates in `buoy`, because this is probably how we're going to join to the benthic data. As a reminder: 

```{r, eval=FALSE}
head(benthic)
head(buoy)
```

So the date formats are different between these two datasets, and so we can't join them as-is. Benthic's date format is `2010-03-12` and in the buoy dataset it is spread across 3 columns (and also has hours and minutes).

So before we can join we need to wrangle those buoy dates. We know the format we want them to look like, so we can combine them into a new column named `date` using `tidyr::unite()`. When we unite these columns it will actually replace the original columns with out new column:

```{r unite}
buoy <- buoy %>%
  unite(date, c(YY_yr, MM_mo, DD_dy), sep = "-")

head(buoy)
```

## Join datasets

Great, let's join these datasets!

We can use [RStudio's data wrangling cheatsheet](http://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) as a reminder: 

![](images/rstudio-cheatsheet-combine-options.png)

Let's go with left join by date:

```{r}
bb_join <- benthic %>%
  left_join(buoy, by = "date")
```

Woah, just from the Environment pane we can see there are A LOT of observations based on this join. What happened? Let's have a look:

```{r, eval=FALSE}
head(bb_join) # kind of hard to see what's going on.

## let's select a few columns and inspect:
bb_join %>%
  select(id_name, x, y, date, hh_hr, mm_mn, WTMP_degC) %>%
  head()
```

OK, so because the buoy data has sampling every 6 minutes, there is a lot of repeated data as a result of the join. Is that what we want? If not, what should we do? 

We could summarize the buoy data by hour or day, or filter the hours that the benthic survey took place. What we do will depend on the science questions you are asking! 

## Your turn

Save, commit, and sync your work. Then, continue the analysis based on what you're interested in. Here are some ideas:


### Explore benthic data

- what other ways could you visualize the data? What questions does bring up?


### Explore buoy data

What are some other things we could do to this data? 

1. Seems like 999.0 is not really a measured °Celsius
    - After confirming with the metadata, we should replace it with NA `stringr::str_replace_all()`
1. `WTMP_degC` does not seem to be numeric (since 999.0 is right there next to 28.6).
    - We could confirm this with `str(buoy)`, then convert to numeric with `buoy <- buoy %>% mutate(WTMP_degC = as.numeric(WTMP_degC))`
    - Why is this a string? So actually all variables in `buoy` are character instead of numeric, and it's because when we originally read in the file the first row was measurement units, which was a character string. So any of these that we want to treat of numbers we are going to have to explicitly change to numeric. 
1. How would you plot a timeseries of temperature change? 

### Explore joined data

- what variables should you compare? Temperature?
- should you summarize species counts first?

### Explore beyond

- Compare a different buoy and benthic pair?

